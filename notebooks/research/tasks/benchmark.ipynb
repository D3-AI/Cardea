{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from mlblocks import add_primitives_path, MLPipeline\n",
    "from pandas.errors import DtypeWarning\n",
    "from sklearn.exceptions import DataConversionWarning, UndefinedMetricWarning\n",
    "\n",
    "from cardea.benchmark.benchmark import benchmark, aggregate_results_by_pipeline, aggregate_results_by_problem\n",
    "from cardea.benchmark.task import create_tasks\n",
    "\n",
    "# Ignore warnings to make the loggings readable. \n",
    "warnings.filterwarnings('ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings('ignore', category=DtypeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '../../../'))\n",
    "\n",
    "# Add customized primitives from a local source.\n",
    "primitives_path = os.path.join(root_path, 'cardea', 'primitives')\n",
    "add_primitives_path(os.path.join(primitives_path, 'jsons'))\n",
    "\n",
    "output_path = os.path.join(root_path, 'benchmark', 'Release v0.1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: Generate tasks from a set of pipelines to solve a list of problems.\n",
    "tasks = create_tasks(dataset_name='mimic-iii', beginning_stage='featurization', optimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-2: Evaluate the tasks and summarize the results of each run. \n",
    "results = benchmark(tasks, tasks_output_dir=output_path)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-3.1: Gain a pipeline-level summary by aggregation.\n",
    "aggregate_results_by_pipeline(results, 'F1 Macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-3.2: Gain a problem-level summary by aggregation.\n",
    "aggregate_results_by_problem(results, 'F1 Macro', record_time=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cardea-venv)",
   "language": "python",
   "name": "cardea-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
