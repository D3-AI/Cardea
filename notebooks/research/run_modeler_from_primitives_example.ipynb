{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeler Primitives Example\n",
    "\n",
    "This notebook looks at how we can change the primitive list to run cardea end-to-end. The first part of the notebook looks at the Cardea class to load a dataset, select a problem, and then featurize the data. To understand more about the cardea class, visit the `appointment_noshow_tutorial` to see the series of transformations applied to the data to create a prediction problem.\n",
    "\n",
    "In the later half of this tutorial, which is what we aim to address, we look at how we can split our dataset into its `X`, and `y` variables, then perform a prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from mlblocks import MLPipeline\n",
    "\n",
    "from cardea import Cardea\n",
    "from cardea.modeling import Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 13 features\n",
      "Elapsed: 00:42 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 10/10 chunks\n"
     ]
    }
   ],
   "source": [
    "# initialize components\n",
    "cd = Cardea()\n",
    "modeler = Modeler()\n",
    "\n",
    "# load data\n",
    "cd.load_data_entityset()\n",
    "\n",
    "# select problem\n",
    "cutoff = cd.select_problem('MissedAppointmentProblemDefinition')\n",
    "\n",
    "# featurize\n",
    "feature_matrix = cd.generate_features(cutoff[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have generated our feature matrix, including the target variable. From here, we wish to prune some of the generated columns and then split our feature matrix into its `X` and `y` variables.\n",
    "\n",
    "To accomplish this, we use the following primitives. Each primitive is responsible for a single task, which in this case is represented by its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    \"cardea.primitives.processing.prune_cols\",\n",
    "    \"cardea.primitives.processing.split_feature_matrix\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use `MLPipeline` from mlblocks to transform our feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (1000, 65)\n",
      "y shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "pipeline = MLPipeline(primitives)\n",
    "X, y = pipeline.predict(feature_matrix, problem='MissedAppointment')\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our model using the same idea of primitives and transformations. In this example, I am using a random forest classifier proceeded by normalizing the data between `[0,1]`.\n",
    "\n",
    "You might be wondering why we have two list of primitives (the previous one and the one below). Ideally, we should have one, but in the curent implementation of Cardea, the modeler expects two variables `X`, and `y`, which are both part of the `feature_matrix` variable before splitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    \"sklearn.preprocessing.MinMaxScaler\",\n",
    "    \"sklearn.ensemble.RandomForestClassifier\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sarah/opt/anaconda3/envs/cardea/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "result = modeler.execute_pipeline(data_frame=X,\n",
    "                                  target=y,\n",
    "                                  primitives_list=[primitives], \n",
    "                                  problem_type='classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
