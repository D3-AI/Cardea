
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>cardea.benchmark.benchmark &#8212; Cardea 0.1.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../../index.html">
    
      <p class="title">Cardea</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../basic_concepts/index.html">Basic Concepts</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../api_reference/index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../community/index.html">Community</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../history.html">Release Notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DAI-Lab/Cardea" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for cardea.benchmark.benchmark</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">dirname</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">mlblocks</span> <span class="kn">import</span> <span class="n">MLPipeline</span>

<span class="kn">from</span> <span class="nn">cardea.modeling.modeler</span> <span class="kn">import</span> <span class="n">Modeler</span>

<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">ROOT_DIR</span> <span class="o">=</span> <span class="n">dirname</span><span class="p">(</span><span class="n">dirname</span><span class="p">(</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))))</span>

<span class="n">CLASSIFICATION_METRICS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;F1 Macro&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">),</span>
    <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                                                                   <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">),</span>
    <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                                                                         <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">),</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">,</span>
    <span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">:</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span>
<span class="p">}</span>

<span class="n">PROBLEM_TYPE</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;LOS&#39;</span><span class="p">:</span> <span class="s1">&#39;classification&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Mortality&#39;</span><span class="p">:</span> <span class="s1">&#39;classification&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Readmission&#39;</span><span class="p">:</span> <span class="s1">&#39;classification&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">TARGET_NAME</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;LOS&#39;</span><span class="p">:</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Mortality&#39;</span><span class="p">:</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Readmission&#39;</span><span class="p">:</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">_scoring_folds</span><span class="p">(</span><span class="n">folds</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Score each fold from the pipeline results.</span>

<span class="sd">    Args:</span>
<span class="sd">        folds (list or dict):</span>
<span class="sd">            a list or a dictionary of pipeline results in each fold, the results consists of a list</span>
<span class="sd">            of prediction values and a list of label values.</span>
<span class="sd">        metrics (dict):</span>
<span class="sd">            a dictionary of metric functions indexed by metric names.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict:</span>
<span class="sd">            aggregated scores calculated from the fold results.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">folds</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">folds</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">folds</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>

    <span class="n">performance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([{</span><span class="n">item</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;predicted&#39;</span><span class="p">])</span>
                                 <span class="k">for</span> <span class="n">item</span><span class="p">,</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds</span><span class="p">])</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">performance</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">scores</span>


<span class="k">def</span> <span class="nf">_split_features_target</span><span class="p">(</span><span class="n">feature_matrix</span><span class="p">,</span> <span class="n">problem_name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Split the features and labels.</span>

<span class="sd">    Args:</span>
<span class="sd">        feature_matrix (pd.DataFrame):</span>
<span class="sd">            a dataframe consists of both feature values and target values.</span>
<span class="sd">        problem_name (str):</span>
<span class="sd">            the name of the problem.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple:</span>
<span class="sd">            features (pd.DataFrame) and target (pd.Series).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">feature_matrix</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">problem_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">features</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">problem_name</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

    <span class="n">target</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">TARGET_NAME</span><span class="p">[</span><span class="n">problem_name</span><span class="p">])</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">target</span>


<div class="viewcode-block" id="aggregate_results_by_pipeline"><a class="viewcode-back" href="../../../api/cardea.benchmark.benchmark.html#cardea.benchmark.benchmark.aggregate_results_by_pipeline">[docs]</a><span class="k">def</span> <span class="nf">aggregate_results_by_pipeline</span><span class="p">(</span><span class="n">performance</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">record_time</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Aggregate the results of each pipeline.</span>

<span class="sd">    Args:</span>
<span class="sd">        performance (pd.DataFrame):</span>
<span class="sd">            the performance of each pipeline execution.</span>
<span class="sd">        metric (str):</span>
<span class="sd">            the name of the target metric for summary.</span>
<span class="sd">        record_time (boolean):</span>
<span class="sd">            whether to the record the elapsed time in the summary.</span>
<span class="sd">        output_path (str):</span>
<span class="sd">            the path to store the results.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame:</span>
<span class="sd">            aggregated performance of each pipeline on each problem.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;Status&#39;</span> <span class="ow">in</span> <span class="n">performance</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">performance</span> <span class="o">=</span> <span class="n">performance</span><span class="p">[</span><span class="n">performance</span><span class="p">[</span><span class="s1">&#39;Status&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;OK&#39;</span><span class="p">]</span>

    <span class="n">problems</span> <span class="o">=</span> <span class="n">performance</span><span class="p">[</span><span class="s1">&#39;Problem Name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
    <span class="n">pipelines</span> <span class="o">=</span> <span class="n">performance</span><span class="p">[</span><span class="s1">&#39;Pipeline Name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

    <span class="n">aggr_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">problem</span> <span class="ow">in</span> <span class="n">problems</span><span class="p">:</span>
        <span class="n">problem_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">pipeline</span> <span class="ow">in</span> <span class="n">pipelines</span><span class="p">:</span>
            <span class="n">runs</span> <span class="o">=</span> <span class="n">_select_runs</span><span class="p">(</span><span class="n">performance</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">)</span>
            <span class="n">problem_dict</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_Average </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">metric</span><span class="p">)]</span> <span class="o">=</span> <span class="n">runs</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">problem_dict</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_Best </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">metric</span><span class="p">)]</span> <span class="o">=</span> <span class="n">runs</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">record_time</span><span class="p">:</span>
                <span class="n">problem_dict</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_Average Elapsed Time(s)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">runs</span><span class="p">[</span><span class="s2">&quot;Elapsed Time(s)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">aggr_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">problem_dict</span><span class="p">)</span>
    <span class="n">aggr_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">aggr_results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">problems</span><span class="p">)</span>
    <span class="n">aggr_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">aggr_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_path</span><span class="p">:</span>
        <span class="n">aggr_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">aggr_df</span></div>


<div class="viewcode-block" id="aggregate_results_by_problem"><a class="viewcode-back" href="../../../api/cardea.benchmark.benchmark.html#cardea.benchmark.benchmark.aggregate_results_by_problem">[docs]</a><span class="k">def</span> <span class="nf">aggregate_results_by_problem</span><span class="p">(</span><span class="n">performance</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">record_time</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Aggregate the results on each problem.</span>

<span class="sd">    Args:</span>
<span class="sd">        performance (pd.DataFrame):</span>
<span class="sd">            the performance of each pipeline execution.</span>
<span class="sd">        metric (str):</span>
<span class="sd">            the name of the target metric for summary.</span>
<span class="sd">        record_time (boolean):</span>
<span class="sd">            whether to the record the elapsed time in the summary.</span>
<span class="sd">        output_path (str):</span>
<span class="sd">            the path to store the results.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame:</span>
<span class="sd">            aggregated performance on each problem.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;Status&#39;</span> <span class="ow">in</span> <span class="n">performance</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">performance</span> <span class="o">=</span> <span class="n">performance</span><span class="p">[</span><span class="n">performance</span><span class="p">[</span><span class="s1">&#39;Status&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;OK&#39;</span><span class="p">]</span>

    <span class="n">problems</span> <span class="o">=</span> <span class="n">performance</span><span class="p">[</span><span class="s1">&#39;Problem Name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
    <span class="n">aggr_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">problem</span> <span class="ow">in</span> <span class="n">problems</span><span class="p">:</span>
        <span class="n">runs</span> <span class="o">=</span> <span class="n">_select_runs</span><span class="p">(</span><span class="n">performance</span><span class="p">,</span> <span class="n">problem</span><span class="p">)</span>
        <span class="n">problem_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;Average </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metric</span><span class="p">):</span> <span class="n">runs</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
            <span class="s2">&quot;Best </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metric</span><span class="p">):</span> <span class="n">runs</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
            <span class="s2">&quot;Best Pipeline&quot;</span><span class="p">:</span> <span class="n">runs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">runs</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(),</span> <span class="s1">&#39;Pipeline Name&#39;</span><span class="p">]</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">record_time</span><span class="p">:</span>
            <span class="n">problem_dict</span><span class="p">[</span><span class="s2">&quot;Average Elapsed Time(s)&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">runs</span><span class="p">[</span><span class="s2">&quot;Elapsed Time(s)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">aggr_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">problem_dict</span><span class="p">)</span>
    <span class="n">aggr_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">aggr_results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">problems</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_path</span><span class="p">:</span>
        <span class="n">aggr_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">aggr_df</span></div>


<span class="k">def</span> <span class="nf">_select_runs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">problem</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pipeline</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">problem</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Problem Name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">problem</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Pipeline Name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">pipeline</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">df</span>


<div class="viewcode-block" id="benchmark"><a class="viewcode-back" href="../../../api/cardea.benchmark.benchmark.html#cardea.benchmark.benchmark.benchmark">[docs]</a><span class="k">def</span> <span class="nf">benchmark</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">save_results</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">save_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_intermedia_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_hyperparameters</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run benchmark testing on a set of tasks. Return detailed results of each run stored in a</span>
<span class="sd">    DataFrame object.</span>

<span class="sd">    Args:</span>
<span class="sd">        tasks (list):</span>
<span class="sd">            a list of task instances storing meta information of each task.</span>
<span class="sd">        metrics (dict):</span>
<span class="sd">            a dictionary of metric functions indexed by metric names.</span>
<span class="sd">        output_path (str):</span>
<span class="sd">            the dir path to store benchmark results and records of each task.</span>
<span class="sd">        save_results (boolean):</span>
<span class="sd">            whether to store the benchmark results.</span>
<span class="sd">        save_intermedia_data (boolean):</span>
<span class="sd">            whether to store the intermedia data including an entity set and a feature matrix if</span>
<span class="sd">            the beginning stage is &quot;data_loader&quot; or &quot;problem_definition&quot;.</span>
<span class="sd">        save_model (boolean):</span>
<span class="sd">            whether to store the trained model.</span>
<span class="sd">        save_hyperparameters (boolean):</span>
<span class="sd">            whether to store the hyperparameters if task.tuned is true.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame:</span>
<span class="sd">            benchmarking results in detail.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

    <span class="n">performance</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_output_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">task_id</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">task_output_path</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">performance</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">evaluate_task</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="n">task_output_path</span><span class="p">,</span>
                                         <span class="n">save_model</span><span class="o">=</span><span class="n">save_model</span><span class="p">,</span>
                                         <span class="n">save_intermedia_data</span><span class="o">=</span><span class="n">save_intermedia_data</span><span class="p">,</span>
                                         <span class="n">save_hyperparameters</span><span class="o">=</span><span class="n">save_hyperparameters</span><span class="p">))</span>
    <span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">performance</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">save_results</span><span class="p">:</span>
        <span class="n">result_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;details.csv&#39;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">result_df</span></div>


<div class="viewcode-block" id="evaluate_task"><a class="viewcode-back" href="../../../api/cardea.benchmark.benchmark.html#cardea.benchmark.benchmark.evaluate_task">[docs]</a><span class="k">def</span> <span class="nf">evaluate_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feature_matrix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">save_intermedia_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_hyperparameters</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run benchmark testing on a task. Save intermedia data, trained models, and optimized</span>
<span class="sd">    hyperparameters. Return testing results.</span>

<span class="sd">    Args:</span>
<span class="sd">        task (Task):</span>
<span class="sd">            a task instance storing meta information of the task.</span>
<span class="sd">        metrics (dict):</span>
<span class="sd">            a dictionary of metric functions indexed by metric names.</span>
<span class="sd">        feature_matrix (pd.DataFrame):</span>
<span class="sd">            a dataframe consists of both feature values and target values.</span>
<span class="sd">        output_path (str):</span>
<span class="sd">            a directory path to store the intermedia data, model and hyperparametes.</span>
<span class="sd">        save_intermedia_data (boolean):</span>
<span class="sd">            whether to store the intermedia data including an entity set and a feature matrix if</span>
<span class="sd">            the beginning stage is &quot;data_loader&quot; or &quot;problem_definition&quot;.</span>
<span class="sd">        save_model (boolean):</span>
<span class="sd">            whether to store the trained model.</span>
<span class="sd">        save_hyperparameters (boolean):</span>
<span class="sd">            whether to store the hyperparameters if task.tuned is true.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list:</span>
<span class="sd">            benchmarking results of each run.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">metrics</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">PROBLEM_TYPE</span><span class="p">[</span><span class="n">task</span><span class="o">.</span><span class="n">problem_name</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">CLASSIFICATION_METRICS</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="c1"># Load pipeline.</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">MLPipeline</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ROOT_DIR</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">path_to_pipeline</span><span class="p">))</span>

    <span class="c1"># Set hyperparameters.</span>
    <span class="k">if</span> <span class="n">task</span><span class="o">.</span><span class="n">path_to_hyperparameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">path_to_hyperparameters</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ROOT_DIR</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">path_to_hyperparameters</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">extension</span> <span class="o">==</span> <span class="s1">&#39;.json&#39;</span><span class="p">:</span>
                <span class="n">init_hyperparameters</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">extension</span> <span class="o">==</span> <span class="s1">&#39;.pkl&#39;</span><span class="p">:</span>
                <span class="n">init_hyperparameters</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unsupported file type </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">extension</span><span class="p">))</span>
        <span class="n">pipeline</span><span class="o">.</span><span class="n">set_hyperparameters</span><span class="p">(</span><span class="n">init_hyperparameters</span><span class="p">)</span>

    <span class="c1"># Load Dataset.</span>
    <span class="k">if</span> <span class="n">feature_matrix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task</span><span class="o">.</span><span class="n">beginning_stage</span> <span class="o">==</span> <span class="s2">&quot;data_loader&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="k">elif</span> <span class="n">task</span><span class="o">.</span><span class="n">beginning_stage</span> <span class="o">==</span> <span class="s2">&quot;problem_definition&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="k">elif</span> <span class="n">task</span><span class="o">.</span><span class="n">beginning_stage</span> <span class="o">==</span> <span class="s2">&quot;featurization&quot;</span><span class="p">:</span>
            <span class="n">feature_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ROOT_DIR</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">path_to_dataset</span><span class="p">),</span>
                <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Beginning stage should be either </span><span class="se">\&quot;</span><span class="s2">data_loader</span><span class="se">\&quot;</span><span class="s2">, &quot;</span>
                         <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">problem_definition</span><span class="se">\&quot;</span><span class="s2"> or </span><span class="se">\&quot;</span><span class="s2">featurization</span><span class="se">\&quot;</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="c1"># Run the pipeline for #task.run_num times and record each run.</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">records</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Records include (pipeline models (pickle), hyperparameters) of each run.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">run_num</span><span class="p">):</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">hyperparameters</span> <span class="o">=</span> <span class="n">_evaluate_pipeline</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">feature_matrix</span><span class="p">,</span>
                                                             <span class="n">task</span><span class="o">.</span><span class="n">pipeline_name</span><span class="p">,</span>
                                                             <span class="n">task</span><span class="o">.</span><span class="n">problem_name</span><span class="p">,</span>
                                                             <span class="n">task</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span>
                                                             <span class="n">task</span><span class="o">.</span><span class="n">beginning_stage</span><span class="p">,</span>
                                                             <span class="n">task</span><span class="o">.</span><span class="n">tuned</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="n">records</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">models</span><span class="p">,</span> <span class="n">hyperparameters</span><span class="p">))</span>

    <span class="c1"># Store the output results.</span>
    <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Initialize the output directory.</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_path</span><span class="p">):</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

        <span class="c1"># Save task meta information</span>
        <span class="n">task</span><span class="o">.</span><span class="n">save_as</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;meta.json&quot;</span><span class="p">),</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span>
        <span class="n">matrix</span> <span class="o">=</span> <span class="s1">&#39;F1 Macro&#39;</span>
        <span class="n">best_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">([</span><span class="n">scores</span><span class="p">[</span><span class="n">matrix</span><span class="p">]</span> <span class="k">for</span> <span class="n">scores</span> <span class="ow">in</span> <span class="n">results</span><span class="p">])</span>
        <span class="n">models</span><span class="p">,</span> <span class="n">hyperparameters</span> <span class="o">=</span> <span class="n">records</span><span class="p">[</span><span class="n">best_index</span><span class="p">]</span>

        <span class="c1"># Save pipeline models if required</span>
        <span class="k">if</span> <span class="n">save_model</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;models.pkl&quot;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

        <span class="c1"># Save pipeline hyperparameters if required</span>
        <span class="k">if</span> <span class="n">save_hyperparameters</span> <span class="ow">and</span> <span class="n">hyperparameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;hyperparameters.pkl&quot;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">hyperparameters</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span></div>


<span class="k">def</span> <span class="nf">_evaluate_pipeline</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">feature_matrix</span><span class="p">,</span> <span class="n">pipeline_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">problem_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">dataset_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beginning_stage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate a pipeline&#39;s performance on a target dataset according to the given metrics.</span>

<span class="sd">    Args:</span>
<span class="sd">        run_id (int):</span>
<span class="sd">            the index to specify the execution to the pipeline.</span>
<span class="sd">        pipeline (MLPipeline):</span>
<span class="sd">            a pipeline instance.</span>
<span class="sd">        feature_matrix (pd.DataFrame):</span>
<span class="sd">            a dataframe consists of both feature values and target values.</span>
<span class="sd">        pipeline_name (str):</span>
<span class="sd">            the name of the pipeline.</span>
<span class="sd">        problem_name (str):</span>
<span class="sd">            the name of the problem.</span>
<span class="sd">        dataset_name (str):</span>
<span class="sd">            the name of the dataset.</span>
<span class="sd">        beginning_stage (str):</span>
<span class="sd">            the stage in which the benchmarking are applied, should be either &quot;data_loader&quot;,</span>
<span class="sd">            &quot;problem_definition&quot;, &quot;featurization&quot;.</span>
<span class="sd">        optimize (boolean):</span>
<span class="sd">            whether to optimize the hyper-parameters of the pipeline.</span>
<span class="sd">        metrics (dict)</span>
<span class="sd">            metric functions indexed by names.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple:</span>
<span class="sd">            pipeline evaluation results including (performance, models, hyperparameters).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">_split_features_target</span><span class="p">(</span><span class="n">feature_matrix</span><span class="p">,</span> <span class="n">problem_name</span><span class="p">)</span>

    <span class="c1"># TODO: digitize the labels in the featurization (problem definition) stage.</span>
    <span class="k">if</span> <span class="n">problem_name</span> <span class="o">==</span> <span class="s1">&#39;LOS&#39;</span> <span class="ow">and</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;mimic-iii&#39;</span><span class="p">:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">metrics</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">PROBLEM_TYPE</span><span class="p">[</span><span class="n">problem_name</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">CLASSIFICATION_METRICS</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="n">modeler</span> <span class="o">=</span> <span class="n">Modeler</span><span class="p">()</span>

    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting pipeline </span><span class="si">{}</span><span class="s2"> for </span><span class="si">{}</span><span class="s2"> problem..&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pipeline_name</span><span class="p">,</span> <span class="n">problem_name</span><span class="p">))</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">pipelines_res</span> <span class="o">=</span> <span class="n">modeler</span><span class="o">.</span><span class="n">execute_pipeline_from_pipeline</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="p">[</span><span class="n">pipeline</span><span class="p">],</span>
                                                               <span class="n">PROBLEM_TYPE</span><span class="p">[</span><span class="n">problem_name</span><span class="p">],</span>
                                                               <span class="n">optimize</span><span class="o">=</span><span class="n">optimize</span><span class="p">,</span>
                                                               <span class="n">minimize_cost</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
                                                               <span class="n">max_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
        <span class="n">hyperparameters</span> <span class="o">=</span> <span class="n">pipelines_res</span><span class="p">[</span><span class="s1">&#39;pipeline0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;hyperparameter&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">models</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="n">fold</span><span class="p">[</span><span class="s1">&#39;pipeline&#39;</span><span class="p">],</span> <span class="s2">&quot;test_index&quot;</span><span class="p">:</span> <span class="n">fold</span><span class="p">[</span><span class="s2">&quot;test_index&quot;</span><span class="p">]}</span>
                  <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">pipelines_res</span><span class="p">[</span><span class="s1">&#39;pipeline0&#39;</span><span class="p">][</span><span class="s1">&#39;folds&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">_scoring_folds</span><span class="p">(</span><span class="n">pipelines_res</span><span class="p">[</span><span class="s1">&#39;pipeline0&#39;</span><span class="p">][</span><span class="s1">&#39;folds&#39;</span><span class="p">],</span> <span class="n">metrics</span><span class="p">)</span>
        <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Elapsed Time(s)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span>
        <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Status&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;OK&#39;</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span>
            <span class="s2">&quot;Exception scoring pipeline </span><span class="si">{}</span><span class="s2"> in problem </span><span class="si">{}</span><span class="s2">, exception </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pipeline_name</span><span class="p">,</span>
                                                                               <span class="n">problem_name</span><span class="p">,</span> <span class="n">ex</span><span class="p">))</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
        <span class="n">hyperparameters</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">models</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">name</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Elapsed Time(s)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span>
        <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Status&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Fail&#39;</span>

    <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Pipeline Name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pipeline_name</span>
    <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Run #&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">run_id</span>
    <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Problem Name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">problem_name</span>
    <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Dataset Name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_name</span>
    <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Beginning Stage&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">beginning_stage</span>
    <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;Tuned&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimize</span>

    <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">hyperparameters</span>
</pre></div>

              </div>
              
              
              <div class='prev-next-bottom'>
                

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2018, MIT Data To AI Lab.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>